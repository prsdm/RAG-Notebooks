{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-dnMwuJHmPy"
      },
      "source": [
        "# RAG - Mixtral Model\n",
        "📒Notebook Created by ❤️ [@prasadmahamulkar](https://x.com/prsdm17).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw4rcbBS4gvm",
        "outputId": "c7466462-d784-49c9-ac69-22012507fbe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U transformers langchain sentence_transformers faiss-gpu huggingface-hub python-dotenv PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgEdv97M4efD"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.llms import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "586a0068c4084f2e921394cfc8ded7a3",
            "a3c60ba298e14ad5af63c82d276a8595",
            "194133ba84364524a0c3354b61789bb1",
            "4498afb6f9db4b60ba1a78ec0f46d050",
            "4c52ca8de1b84d9b8b127d3e0f63b902",
            "dd612ecca05c44ae95494d4df0a26c25",
            "c003f7dc1dd84fec9a6d93d245f695a5",
            "9b6e674a797947e5a803f13199c9f393",
            "14b73539cca34368ab0c3c9a51c4ce22",
            "bd97a99e9d9f408ea6bd96bfbc6b9416",
            "f219ef260af248cea11590a7b5009f21",
            "27a00475e22b4858a1b01142b0e7e1d6",
            "e9494c6a4d9842e7b4c9984a7485e64f",
            "181e3df8efa04d09b52c10de45b4fe44",
            "ada9ada4a2d44531aaf99fd04c82a240",
            "a2236330a81443e59e4afe9e5c66342a",
            "b4860121c90c444f92850f9d47b4e192",
            "b6bb278560c1432599add3c3928b4546",
            "4583b599087245088f698aa39af1a4ee",
            "cec1b0f8539842fb89e6f25e3ba159a4",
            "d2426b01078a412fb7990dd6d803aa07",
            "e90a898c9a25462fbb677a8b2dc3045e",
            "b60315e7fa764b098b91c0cd81b425c4",
            "f44c0d827b384ee8a77bb35f1bd1b6e1",
            "86a7be187e4e4c5982024f78e2e5e965",
            "9a0d1c78d6dd4e4a99ba02865bcc5459",
            "686659ad50c445dab3551d6fea08983c",
            "ff68c7f603a0400e99105f5d4b03d0b7",
            "51e539707ea04c62ada537b425a69d20",
            "afdbc23d7f57497a949e7a5638ff2a12",
            "9808d20b57cf420a8538995340372573",
            "32d13f8838e54993b2cf37fecd028791"
          ]
        },
        "id": "zRwXkiBP5jr1",
        "outputId": "0d4b28d7-611f-4347-fe06-92a490f78cbf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "586a0068c4084f2e921394cfc8ded7a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SmdbniBF57Ye",
        "outputId": "f8794758-e994-4468-e09d-43142d8da5af"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'QL ORA: Efficient Finetuning of Quantized LLMs\\nTim Dettmers∗Artidoro Pagnoni∗Ari Holtzman\\nLuke Zettl'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_pdf_text(pdf_docs):\n",
        "    text = \"\"\n",
        "    for pdf in pdf_docs:\n",
        "        pdf_reader = PdfReader(pdf)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "text = get_pdf_text([\"/content/qlora_paper.pdf\"])\n",
        "\n",
        "text[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "-bu2wYlz6Iw1",
        "outputId": "97a85053-826a-4f2c-edac-1302f903d0e9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'QL ORA: Efficient Finetuning of Quantized LLMs\\nTim Dettmers∗Artidoro Pagnoni∗Ari Holtzman\\nLuke Zettlemoyer\\nUniversity of Washington\\n{dettmers,artidoro,ahai,lsz}@cs.washington.edu\\nAbstract\\nWe present QLORA, an efficient finetuning approach that reduces memory us-\\nage enough to finetune a 65B parameter model on a single 48GB GPU while\\npreserving full 16-bit finetuning task performance. QLORAbackpropagates gradi-\\nents through a frozen, 4-bit quantized pretrained language model into Low Rank\\nAdapters (LoRA). Our best model family, which we name Guanaco , outperforms\\nall previous openly released models on the Vicuna benchmark, reaching 99.3%\\nof the performance level of ChatGPT while only requiring 24 hours of finetuning\\non a single GPU. QLORAintroduces a number of innovations to save memory\\nwithout sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that\\nis information theoretically optimal for normally distributed weights (b) Double'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "def get_text_chunks(text):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks\n",
        "chunk_text = get_text_chunks(text)\n",
        "chunk_text[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_M4ZJHx6eJr"
      },
      "outputs": [],
      "source": [
        "model = \"BAAI/bge-small-en-v1.5\"\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model, encode_kwargs=encode_kwargs, model_kwargs={\"device\": \"cpu\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl1H98v27Z_O",
        "outputId": "44d5bba3-6631-4b75-806d-794cf3b16ecf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.10743825137615204,\n",
              " 0.057859934866428375,\n",
              " -0.11160264164209366,\n",
              " 0.04787628725171089,\n",
              " -0.10750839114189148,\n",
              " 0.010762185789644718,\n",
              " 0.07565398514270782,\n",
              " 0.028037123382091522,\n",
              " 0.09083810448646545,\n",
              " 0.0040848273783922195]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "check = embeddings.embed_query(\"what is Qlora?\")\n",
        "check[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMsEMWL-o4QL"
      },
      "outputs": [],
      "source": [
        "vectorstore = FAISS.from_texts(texts=chunk_text, embedding=embeddings)\n",
        "\n",
        "retriever = vectorstore.as_retriever(score_threshold = 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAYkWral7Fgi",
        "outputId": "078a2f85-273b-4674-b8c5-089cce45f6a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='large corporations and small teams with consumer GPUs.\\nAnother potential source of impact is deployment to mobile phones. We believe our QLORAmethod\\nmight enable the critical milestone of enabling the finetuning of LLMs on phones and other low\\nresource settings. While 7B models were shown to be able to be run on phones before, QLORAis\\nthe first method that would enable the finetuning of such models. We estimate that with an iPhone 12\\nPlus, QLORAcan finetune 3 million tokens per night while the phone is charging. While finetuned\\n7B models do not reach the quality of ChatGPT, we believe that the quality is good enough to enable\\nnovel applications that have not been possible before due to privacy or LLM quality issues. QLORA\\ncan help enable privacy-preserving usage of LLMs, where users can own and manage their own data\\nand models, while simultaneously making LLMs easier to deploy.\\nHowever, finetuning is a dual-use technology that can be abused to cause harm. Widespread use of'),\n",
              " Document(page_content='without degrading performance.\\nk-bit QL ORAmatches 16-bit full finetuning and\\n16-bit LoRA performance Recent findings have\\nestablished that 4-bit quantization for inference is\\n6Table 3: Experiments comparing 16-bit BrainFloat (BF16), 8-bit Integer (Int8), 4-bit Float (FP4), and 4-\\nbit NormalFloat (NF4) on GLUE and Super-NaturalInstructions. QLORAreplicates 16-bit LoRA and full-\\nfinetuning.\\nDataset GLUE (Acc.) Super-NaturalInstructions (RougeL)\\nModel RoBERTa-large T5-80M T5-250M T5-780M T5-3B T5-11B\\nBF16 88.6 40.1 42.1 48.0 54.3 62.0\\nBF16 replication 88.6 40.0 42.2 47.3 54.9 -\\nLoRA BF16 88.8 40.5 42.6 47.1 55.4 60.7\\nQLORA Int8 88.8 40.4 42.9 45.4 56.5 60.7\\nQLORA FP4 88.6 40.3 42.4 47.5 55.6 60.9\\nQLORA NF4 + DQ - 40.4 42.7 47.7 55.3 60.9\\npossible, but leads to performance degradation rel-\\native to 16-bit [ 13,18]. This raises the crucial question of whether the lost performance can be\\nrecovered by conducting 4-bit adapter finetuning. We test this for two setups.'),\n",
              " Document(page_content='prevent memory spikes during gradient checkpointing from causing out-of-memory errors that have\\ntraditionally made finetuning on a single machine difficult for large models.\\nQLORAhas one low-precision storage data type, in our case usually 4-bit, and one computation data\\ntype that is usually BFloat16. In practice, this means whenever a QLORAweight tensor is used, we\\ndequantize the tensor to BFloat16, and then perform a matrix multiplication in 16-bit.\\nWe now discuss the components of QL ORA followed by a formal definition of QL ORA.\\n4-bit NormalFloat Quantization The NormalFloat (NF) data type builds on Quantile Quantization\\n[15] which is an information-theoretically optimal data type that ensures each quantization bin has an\\nequal number of values assigned from the input tensor. Quantile quantization works by estimating\\nthe quantile of the input tensor through the empirical cumulative distribution function.'),\n",
              " Document(page_content='automatically evicted to CPU RAM when the GPU runs out-of-memory and paged back into GPU\\nmemory when the memory is needed in the optimizer update step.\\nQL ORA.Using the components described above, we define QLORAfor a single linear layer in\\nthe quantized base model with a single LoRA adapter as follows:\\nYBF16=XBF16doubleDequant (cFP32\\n1, ck-bit\\n2,WNF4) +XBF16LBF16\\n1LBF16\\n2, (5)\\nwhere doubleDequant (·)is defined as:\\ndoubleDequant (cFP32\\n1, ck-bit\\n2,Wk-bit) =dequant (dequant (cFP32\\n1, ck-bit\\n2),W4bit) =WBF16,(6)\\nWe use NF4 for Wand FP8 for c2. We use a blocksize of 64 for Wfor higher quantization precision\\nand a blocksize of 256 for c2to conserve memory.\\nFor parameter updates only the gradient with respect to the error for the adapters weights∂E\\n∂Liare\\nneeded, and not for 4-bit weights∂E\\n∂W. However, the calculation of∂E\\n∂Lientails the calculation of∂X\\n∂W\\nwhich proceeds via equation (5) with dequantization from storage WNF4to computation data type\\nWBF16to calculate the derivative∂X')]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = retriever.get_relevant_documents(\"what is Qlora?\")\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCxq5PRk75JR"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "                     model_kwargs={\"temperature\": 0.1, \"max_length\": 1048},\n",
        "                huggingfacehub_api_token=\"YOUR_HUGGINGFACEHUB_API_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqjf4O_qFbLj"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm, retriever=vectorstore.as_retriever(), memory=memory\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7vOSWRIFhpg",
        "outputId": "3dcac9c0-02e9-4322-9e97-0d93621371b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nlarge corporations and small teams with consumer GPUs.\\nAnother potential source of impact is deployment to mobile phones. We believe our QLORAmethod\\nmight enable the critical milestone of enabling the finetuning of LLMs on phones and other low\\nresource settings. While 7B models were shown to be able to be run on phones before, QLORAis\\nthe first method that would enable the finetuning of such models. We estimate that with an iPhone 12\\nPlus, QLORAcan finetune 3 million tokens per night while the phone is charging. While finetuned\\n7B models do not reach the quality of ChatGPT, we believe that the quality is good enough to enable\\nnovel applications that have not been possible before due to privacy or LLM quality issues. QLORA\\ncan help enable privacy-preserving usage of LLMs, where users can own and manage their own data\\nand models, while simultaneously making LLMs easier to deploy.\\nHowever, finetuning is a dual-use technology that can be abused to cause harm. Widespread use of\\n\\nwithout degrading performance.\\nk-bit QL ORAmatches 16-bit full finetuning and\\n16-bit LoRA performance Recent findings have\\nestablished that 4-bit quantization for inference is\\n6Table 3: Experiments comparing 16-bit BrainFloat (BF16), 8-bit Integer (Int8), 4-bit Float (FP4), and 4-\\nbit NormalFloat (NF4) on GLUE and Super-NaturalInstructions. QLORAreplicates 16-bit LoRA and full-\\nfinetuning.\\nDataset GLUE (Acc.) Super-NaturalInstructions (RougeL)\\nModel RoBERTa-large T5-80M T5-250M T5-780M T5-3B T5-11B\\nBF16 88.6 40.1 42.1 48.0 54.3 62.0\\nBF16 replication 88.6 40.0 42.2 47.3 54.9 -\\nLoRA BF16 88.8 40.5 42.6 47.1 55.4 60.7\\nQLORA Int8 88.8 40.4 42.9 45.4 56.5 60.7\\nQLORA FP4 88.6 40.3 42.4 47.5 55.6 60.9\\nQLORA NF4 + DQ - 40.4 42.7 47.7 55.3 60.9\\npossible, but leads to performance degradation rel-\\native to 16-bit [ 13,18]. This raises the crucial question of whether the lost performance can be\\nrecovered by conducting 4-bit adapter finetuning. We test this for two setups.\\n\\nprevent memory spikes during gradient checkpointing from causing out-of-memory errors that have\\ntraditionally made finetuning on a single machine difficult for large models.\\nQLORAhas one low-precision storage data type, in our case usually 4-bit, and one computation data\\ntype that is usually BFloat16. In practice, this means whenever a QLORAweight tensor is used, we\\ndequantize the tensor to BFloat16, and then perform a matrix multiplication in 16-bit.\\nWe now discuss the components of QL ORA followed by a formal definition of QL ORA.\\n4-bit NormalFloat Quantization The NormalFloat (NF) data type builds on Quantile Quantization\\n[15] which is an information-theoretically optimal data type that ensures each quantization bin has an\\nequal number of values assigned from the input tensor. Quantile quantization works by estimating\\nthe quantile of the input tensor through the empirical cumulative distribution function.\\n\\nautomatically evicted to CPU RAM when the GPU runs out-of-memory and paged back into GPU\\nmemory when the memory is needed in the optimizer update step.\\nQL ORA.Using the components described above, we define QLORAfor a single linear layer in\\nthe quantized base model with a single LoRA adapter as follows:\\nYBF16=XBF16doubleDequant (cFP32\\n1, ck-bit\\n2,WNF4) +XBF16LBF16\\n1LBF16\\n2, (5)\\nwhere doubleDequant (·)is defined as:\\ndoubleDequant (cFP32\\n1, ck-bit\\n2,Wk-bit) =dequant (dequant (cFP32\\n1, ck-bit\\n2),W4bit) =WBF16,(6)\\nWe use NF4 for Wand FP8 for c2. We use a blocksize of 64 for Wfor higher quantization precision\\nand a blocksize of 256 for c2to conserve memory.\\nFor parameter updates only the gradient with respect to the error for the adapters weights∂E\\n∂Liare\\nneeded, and not for 4-bit weights∂E\\n∂W. However, the calculation of∂E\\n∂Lientails the calculation of∂X\\n∂W\\nwhich proceeds via equation (5) with dequantization from storage WNF4to computation data type\\nWBF16to calculate the derivative∂X\\n\\nQuestion: What is Qlora?\\nHelpful Answer: QLORA is a method for quantizing large language models (LLMs) to enable their finetuning on consumer GPUs and mobile phones. It uses a low-precision storage data type, such as 4-bit, and a computation data type, such as BFloat16, to reduce memory usage and enable finetuning on a single machine without out-of-memory errors. QLORA also uses NormalFloat quantization, which ensures each quantization bin\"}"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_chain({\"question\": \"What is Qlora?\"}, return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_nn8PbHGl-U"
      },
      "source": [
        "# If you want understand what exactly the model is doing, you can use this code:\n",
        "prompt is not good but you get the idea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnulgGN47vCS"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "<s>[INST] <<SYS>>\n",
        "Act as a Qlora Expert. Use the following information to answer the question at the end.\n",
        "<</SYS>>\n",
        "\n",
        "{context}\n",
        "\n",
        "{question} [/INST]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "PROMPT = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                            chain_type=\"stuff\",\n",
        "                            retriever=retriever,\n",
        "                            input_key=\"query\",\n",
        "                            return_source_documents=True,\n",
        "                            chain_type_kwargs={\"prompt\": PROMPT}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWUlez3_-5QB",
        "outputId": "8d3ca824-b8af-4e69-e160-0d1cc3de5de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] <<SYS>>\n",
            "Act as a Qlora Expert. Use the following information to answer the question at the end.\n",
            "<</SYS>>\n",
            " \n",
            "large corporations and small teams with consumer GPUs.\n",
            "Another potential source of impact is deployment to mobile phones. We believe our QLORAmethod\n",
            "might enable the critical milestone of enabling the finetuning of LLMs on phones and other low\n",
            "resource settings. While 7B models were shown to be able to be run on phones before, QLORAis\n",
            "the first method that would enable the finetuning of such models. We estimate that with an iPhone 12\n",
            "Plus, QLORAcan finetune 3 million tokens per night while the phone is charging. While finetuned\n",
            "7B models do not reach the quality of ChatGPT, we believe that the quality is good enough to enable\n",
            "novel applications that have not been possible before due to privacy or LLM quality issues. QLORA\n",
            "can help enable privacy-preserving usage of LLMs, where users can own and manage their own data\n",
            "and models, while simultaneously making LLMs easier to deploy.\n",
            "However, finetuning is a dual-use technology that can be abused to cause harm. Widespread use of\n",
            "\n",
            "without degrading performance.\n",
            "k-bit QL ORAmatches 16-bit full finetuning and\n",
            "16-bit LoRA performance Recent findings have\n",
            "established that 4-bit quantization for inference is\n",
            "6Table 3: Experiments comparing 16-bit BrainFloat (BF16), 8-bit Integer (Int8), 4-bit Float (FP4), and 4-\n",
            "bit NormalFloat (NF4) on GLUE and Super-NaturalInstructions. QLORAreplicates 16-bit LoRA and full-\n",
            "finetuning.\n",
            "Dataset GLUE (Acc.) Super-NaturalInstructions (RougeL)\n",
            "Model RoBERTa-large T5-80M T5-250M T5-780M T5-3B T5-11B\n",
            "BF16 88.6 40.1 42.1 48.0 54.3 62.0\n",
            "BF16 replication 88.6 40.0 42.2 47.3 54.9 -\n",
            "LoRA BF16 88.8 40.5 42.6 47.1 55.4 60.7\n",
            "QLORA Int8 88.8 40.4 42.9 45.4 56.5 60.7\n",
            "QLORA FP4 88.6 40.3 42.4 47.5 55.6 60.9\n",
            "QLORA NF4 + DQ - 40.4 42.7 47.7 55.3 60.9\n",
            "possible, but leads to performance degradation rel-\n",
            "ative to 16-bit [ 13,18]. This raises the crucial question of whether the lost performance can be\n",
            "recovered by conducting 4-bit adapter finetuning. We test this for two setups.\n",
            "\n",
            "prevent memory spikes during gradient checkpointing from causing out-of-memory errors that have\n",
            "traditionally made finetuning on a single machine difficult for large models.\n",
            "QLORAhas one low-precision storage data type, in our case usually 4-bit, and one computation data\n",
            "type that is usually BFloat16. In practice, this means whenever a QLORAweight tensor is used, we\n",
            "dequantize the tensor to BFloat16, and then perform a matrix multiplication in 16-bit.\n",
            "We now discuss the components of QL ORA followed by a formal definition of QL ORA.\n",
            "4-bit NormalFloat Quantization The NormalFloat (NF) data type builds on Quantile Quantization\n",
            "[15] which is an information-theoretically optimal data type that ensures each quantization bin has an\n",
            "equal number of values assigned from the input tensor. Quantile quantization works by estimating\n",
            "the quantile of the input tensor through the empirical cumulative distribution function.\n",
            "\n",
            "automatically evicted to CPU RAM when the GPU runs out-of-memory and paged back into GPU\n",
            "memory when the memory is needed in the optimizer update step.\n",
            "QL ORA.Using the components described above, we define QLORAfor a single linear layer in\n",
            "the quantized base model with a single LoRA adapter as follows:\n",
            "YBF16=XBF16doubleDequant (cFP32\n",
            "1, ck-bit\n",
            "2,WNF4) +XBF16LBF16\n",
            "1LBF16\n",
            "2, (5)\n",
            "where doubleDequant (·)is defined as:\n",
            "doubleDequant (cFP32\n",
            "1, ck-bit\n",
            "2,Wk-bit) =dequant (dequant (cFP32\n",
            "1, ck-bit\n",
            "2),W4bit) =WBF16,(6)\n",
            "We use NF4 for Wand FP8 for c2. We use a blocksize of 64 for Wfor higher quantization precision\n",
            "and a blocksize of 256 for c2to conserve memory.\n",
            "For parameter updates only the gradient with respect to the error for the adapters weights∂E\n",
            "∂Liare\n",
            "needed, and not for 4-bit weights∂E\n",
            "∂W. However, the calculation of∂E\n",
            "∂Lientails the calculation of∂X\n",
            "∂W\n",
            "which proceeds via equation (5) with dequantization from storage WNF4to computation data type\n",
            "WBF16to calculate the derivative∂X\n",
            " \n",
            "What is Qlora? [/INST]\n",
            "\n",
            "QLORA is a method for finetuning Large Language Models (LLMs) on consumer GPUs and mobile phones, which was developed to enable privacy-preserving usage of LLMs and make them easier to deploy. It is a dual-use technology that can be used to improve the performance of LLMs while also having the potential to be abused to cause harm.\n",
            "\n",
            "QLORA can finetune 3 million tokens per night on an iPhone 12\n"
          ]
        }
      ],
      "source": [
        "output_query = chain('What is Qlora?')\n",
        "print(output_query[\"result\"].strip())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14b73539cca34368ab0c3c9a51c4ce22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "181e3df8efa04d09b52c10de45b4fe44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194133ba84364524a0c3354b61789bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bd97a99e9d9f408ea6bd96bfbc6b9416",
            "placeholder": "​",
            "style": "IPY_MODEL_f219ef260af248cea11590a7b5009f21",
            "value": ""
          }
        },
        "27a00475e22b4858a1b01142b0e7e1d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d13f8838e54993b2cf37fecd028791": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4498afb6f9db4b60ba1a78ec0f46d050": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_27a00475e22b4858a1b01142b0e7e1d6",
            "style": "IPY_MODEL_e9494c6a4d9842e7b4c9984a7485e64f",
            "value": true
          }
        },
        "4583b599087245088f698aa39af1a4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c52ca8de1b84d9b8b127d3e0f63b902": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_181e3df8efa04d09b52c10de45b4fe44",
            "style": "IPY_MODEL_ada9ada4a2d44531aaf99fd04c82a240",
            "tooltip": ""
          }
        },
        "51e539707ea04c62ada537b425a69d20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "586a0068c4084f2e921394cfc8ded7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2426b01078a412fb7990dd6d803aa07",
              "IPY_MODEL_e90a898c9a25462fbb677a8b2dc3045e",
              "IPY_MODEL_b60315e7fa764b098b91c0cd81b425c4",
              "IPY_MODEL_f44c0d827b384ee8a77bb35f1bd1b6e1"
            ],
            "layout": "IPY_MODEL_c003f7dc1dd84fec9a6d93d245f695a5"
          }
        },
        "686659ad50c445dab3551d6fea08983c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86a7be187e4e4c5982024f78e2e5e965": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9808d20b57cf420a8538995340372573": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a0d1c78d6dd4e4a99ba02865bcc5459": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b6e674a797947e5a803f13199c9f393": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2236330a81443e59e4afe9e5c66342a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3c60ba298e14ad5af63c82d276a8595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b6e674a797947e5a803f13199c9f393",
            "placeholder": "​",
            "style": "IPY_MODEL_14b73539cca34368ab0c3c9a51c4ce22",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ada9ada4a2d44531aaf99fd04c82a240": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "afdbc23d7f57497a949e7a5638ff2a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4860121c90c444f92850f9d47b4e192": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b60315e7fa764b098b91c0cd81b425c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51e539707ea04c62ada537b425a69d20",
            "placeholder": "​",
            "style": "IPY_MODEL_afdbc23d7f57497a949e7a5638ff2a12",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "b6bb278560c1432599add3c3928b4546": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4583b599087245088f698aa39af1a4ee",
            "placeholder": "​",
            "style": "IPY_MODEL_cec1b0f8539842fb89e6f25e3ba159a4",
            "value": "Connecting..."
          }
        },
        "bd97a99e9d9f408ea6bd96bfbc6b9416": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c003f7dc1dd84fec9a6d93d245f695a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "cec1b0f8539842fb89e6f25e3ba159a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2426b01078a412fb7990dd6d803aa07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a7be187e4e4c5982024f78e2e5e965",
            "placeholder": "​",
            "style": "IPY_MODEL_9a0d1c78d6dd4e4a99ba02865bcc5459",
            "value": "Token is valid (permission: write)."
          }
        },
        "dd612ecca05c44ae95494d4df0a26c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2236330a81443e59e4afe9e5c66342a",
            "placeholder": "​",
            "style": "IPY_MODEL_b4860121c90c444f92850f9d47b4e192",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e90a898c9a25462fbb677a8b2dc3045e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686659ad50c445dab3551d6fea08983c",
            "placeholder": "​",
            "style": "IPY_MODEL_ff68c7f603a0400e99105f5d4b03d0b7",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "e9494c6a4d9842e7b4c9984a7485e64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f219ef260af248cea11590a7b5009f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f44c0d827b384ee8a77bb35f1bd1b6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9808d20b57cf420a8538995340372573",
            "placeholder": "​",
            "style": "IPY_MODEL_32d13f8838e54993b2cf37fecd028791",
            "value": "Login successful"
          }
        },
        "ff68c7f603a0400e99105f5d4b03d0b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
